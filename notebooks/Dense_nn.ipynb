{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, target_names, title):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'{title} - Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, X_test, y_test_labels, target_names, model_name):\n",
    "    print(f\"\\n--- Evaluación de {model_name} en el Conjunto de Prueba ---\")\n",
    "    y_pred_labels = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    precision = precision_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "    kappa = cohen_kappa_score(y_test_labels, y_pred_labels)\n",
    "    print(f\"\\nMétricas de Evaluación ({model_name}):\")\n",
    "    print(f\"Precisión (Accuracy): {accuracy:.4f}\")\n",
    "    print(f\"Precisión (Precision - Weighted): {precision:.4f}\")\n",
    "    print(f\"Exhaustividad (Recall - Weighted): {recall:.4f}\")\n",
    "    print(f\"Puntuación F1 (F1-score - Weighted): {f1:.4f}\")\n",
    "    print(f\"Kappa de Cohen: {kappa:.4f}\")\n",
    "    print(\"\\nReporte Detallado de Clasificación:\")\n",
    "    print(classification_report(y_test_labels, y_pred_labels, target_names=target_names, zero_division=0))\n",
    "    plot_confusion_matrix(y_test_labels, y_pred_labels, target_names, model_name)\n",
    "    return y_test_labels, y_pred_labels\n",
    "\n",
    "# Carga y preparación de datos\n",
    "input_folder = '../data_processed'\n",
    "input_filename = 'fifa_tweets_clean.csv'\n",
    "input_csv_file = os.path.join(input_folder, input_filename)\n",
    "\n",
    "df = pd.read_csv(input_csv_file)\n",
    "df_clean = df[df['sentiment_label'] != -1].copy()\n",
    "df_clean.dropna(subset=['test_clean', 'sentiment_label'], inplace=True)\n",
    "\n",
    "texts = df_clean['test_clean'].astype(str).tolist()\n",
    "labels = df_clean['sentiment_label'].astype(int).values\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "MAX_WORDS = 38000\n",
    "MAX_LEN = 60\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y = labels\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Tamaño del conjunto para GridSearch: {X_train_val.shape[0]}\")\n",
    "print(f\"Tamaño del conjunto de prueba final: {X_test.shape[0]}\")\n",
    "\n",
    "# Modelo\n",
    "def create_model(neurons_l1=128, dropout_rate=0.2, optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(MAX_LEN,), name=\"input_layer\"),\n",
    "        Embedding(input_dim=MAX_WORDS, output_dim=128),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(neurons_l1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Grid Search\n",
    "print(\"\\n--- Iniciando Búsqueda de Hiperparámetros con GridSearchCV ---\")\n",
    "\n",
    "model_for_grid = KerasClassifier(\n",
    "    model=create_model,\n",
    "    verbose=0,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    callbacks=[History()]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'model__neurons_l1': [64, 128],\n",
    "    'model__dropout_rate': [0.2, 0.4],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'batch_size': [64],\n",
    "    'epochs': [10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_for_grid,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid_search_result = grid_search.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(\"\\n--- Resultados de GridSearchCV ---\")\n",
    "print(f\"Mejor puntuación (accuracy): {grid_search_result.best_score_:.4f}\")\n",
    "print(\"Mejores hiperparámetros:\", grid_search_result.best_params_)\n",
    "\n",
    "best_model = grid_search_result.best_estimator_\n",
    "target_names = ['negative (0)', 'neutral (1)', 'positive (2)']\n",
    "evaluate_model(best_model, X_test, y_test, target_names, \"Mejor Modelo Encontrado por GridSearchCV\")\n",
    "\n",
    "history = best_model.model_.history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.title(\"Accuracy por Epoch\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.title(\"Loss por Epoch\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
