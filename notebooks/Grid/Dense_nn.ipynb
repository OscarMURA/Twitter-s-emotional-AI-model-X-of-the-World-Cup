{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             cohen_kappa_score, confusion_matrix, classification_report)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "def plot_history(history, title):\n",
    "    \"\"\"\n",
    "    Grafica el historial de entrenamiento y validación (accuracy y loss).\n",
    "    \"\"\"\n",
    "    if not isinstance(history, History) or not history.history:\n",
    "        print(f\"Advertencia: No se pudo graficar el historial para '{title}' (objeto history no válido o vacío).\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if 'accuracy' in history.history:\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    else:\n",
    "        print(\"Advertencia: No se encontraron datos de 'val_accuracy' en el historial.\")\n",
    "    plt.title(f'{title} - Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if 'loss' in history.history:\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    else:\n",
    "        print(\"Advertencia: No se encontraron datos de 'val_loss' en el historial.\")\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, target_names, title):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'{title} - Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, X_test, y_test_labels, target_names, model_name):\n",
    "    print(f\"\\n--- Evaluación de {model_name} en el Conjunto de Prueba ---\")\n",
    "    \n",
    "    y_pred_probs = model.predict(X_test)\n",
    "\n",
    "    if y_pred_probs.ndim > 1 and y_pred_probs.shape[1] > 1:\n",
    "        y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    else:\n",
    "        y_pred_labels = y_pred_probs\n",
    "\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    precision = precision_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "    kappa = cohen_kappa_score(y_test_labels, y_pred_labels)\n",
    "    print(f\"\\nMétricas de Evaluación ({model_name}):\")\n",
    "    print(f\"Precisión (Accuracy): {accuracy:.4f}\")\n",
    "    print(f\"Precisión (Precision - Weighted): {precision:.4f}\")\n",
    "    print(f\"Exhaustividad (Recall - Weighted): {recall:.4f}\")\n",
    "    print(f\"Puntuación F1 (F1-score - Weighted): {f1:.4f}\")\n",
    "    print(f\"Kappa de Cohen: {kappa:.4f}\")\n",
    "    print(\"\\nReporte Detallado de Clasificación:\")\n",
    "    print(classification_report(y_test_labels, y_pred_labels, target_names=target_names, zero_division=0))\n",
    "    plot_confusion_matrix(y_test_labels, y_pred_labels, target_names, model_name)\n",
    "    return y_test_labels, y_pred_labels\n",
    "\n",
    "# --- Carga y preparación de datos ---\n",
    "input_folder = '../data_processed'\n",
    "input_filename = 'fifa_tweets_clean.csv'\n",
    "input_csv_file = os.path.join(input_folder, input_filename)\n",
    "\n",
    "df = pd.read_csv(input_csv_file)\n",
    "df_clean = df[df['sentiment_label'] != -1].copy()\n",
    "df_clean.dropna(subset=['test_clean', 'sentiment_label'], inplace=True)\n",
    "\n",
    "texts = df_clean['test_clean'].astype(str).tolist()\n",
    "labels = df_clean['sentiment_label'].astype(int).values\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "MAX_WORDS = 38000\n",
    "MAX_LEN = 60\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y = labels\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Tamaño del conjunto para GridSearch: {X_train_val.shape[0]}\")\n",
    "print(f\"Tamaño del conjunto de prueba final: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "def create_model(neurons_l1=128, dropout_rate=0.2, optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(MAX_LEN,), name=\"input_layer\"),\n",
    "        Embedding(input_dim=MAX_WORDS, output_dim=128),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(neurons_l1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hiperparámetros\n",
    "print(\"\\n--- Iniciando Búsqueda de Hiperparámetros con GridSearchCV ---\")\n",
    "\n",
    "model_for_grid = KerasClassifier(\n",
    "    model=create_model,\n",
    "    verbose=0,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'model__neurons_l1': [64, 128],\n",
    "    'model__dropout_rate': [0.2, 0.4],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'batch_size': [32,64],\n",
    "    'epochs': [6,10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_for_grid,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid_search_result = grid_search.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(\"\\n--- Resultados de GridSearchCV ---\")\n",
    "print(f\"Mejor puntuación (accuracy) en validación cruzada: {grid_search_result.best_score_:.4f}\")\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search_result.best_params_)\n",
    "\n",
    "print(\"\\n--- Re-entrenando el mejor modelo en todo el conjunto de entrenamiento/validación ---\")\n",
    "\n",
    "best_params = grid_search_result.best_params_\n",
    "best_neurons_l1 = best_params['model__neurons_l1']\n",
    "best_dropout_rate = best_params['model__dropout_rate']\n",
    "best_optimizer = best_params['optimizer']\n",
    "best_batch_size = best_params['batch_size']\n",
    "best_epochs = best_params['epochs']\n",
    "\n",
    "# Nueva instancia del modelo\n",
    "final_model = create_model(\n",
    "    neurons_l1=best_neurons_l1,\n",
    "    dropout_rate=best_dropout_rate,\n",
    "    optimizer=best_optimizer\n",
    ")\n",
    "print(\"\\nArquitectura del modelo final:\")\n",
    "final_model.summary()\n",
    "\n",
    "# Modelo final y guardar el historial.\n",
    "history = final_model.fit(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    epochs=best_epochs,\n",
    "    batch_size=best_batch_size,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_history(history, \"Curvas de Aprendizaje del Mejor Modelo\")\n",
    "\n",
    "target_names = ['negative (0)', 'neutral (1)', 'positive (2)']\n",
    "evaluate_model(final_model, X_test, y_test, target_names, \"Mejor Modelo (Re-entrenado)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
