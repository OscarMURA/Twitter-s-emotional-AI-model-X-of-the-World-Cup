{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, cohen_kappa_score, confusion_matrix, \n",
    "                             classification_report)\n",
    "\n",
    "MAX_WORDS = 50000\n",
    "MAX_LEN = 100\n",
    "EMBEDDING_DIM = 150\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 64\n",
    "TARGET_NAMES = ['negative (0)', 'neutral (1)', 'positive (2)']\n",
    "SENTIMENT_MAP_INV = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "def plot_history(history: History, title: str):\n",
    "    if not isinstance(history, History):\n",
    "        print(f\"Advertencia: No se pudo graficar historial para '{title}'.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for i, metric in enumerate(['accuracy', 'loss']):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        if f'val_{metric}' in history.history:\n",
    "            plt.plot(history.history[f'val_{metric}'], label='Val')\n",
    "        if metric in history.history:\n",
    "            plt.plot(history.history[metric], label='Train')\n",
    "        plt.title(f'{title} - {metric.capitalize()}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, target_names, title: str):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'{title} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, target_names, model_name: str):\n",
    "    print(f\"\\n--- Evaluación del Modelo: {model_name} ---\")\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "    \n",
    "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "    print(f\"Cohen's Kappa: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    plot_confusion_matrix(y_test, y_pred, target_names, model_name)\n",
    "    return y_test, y_pred\n",
    "\n",
    "def predict_sentiment(text: str, model, tokenizer: Tokenizer, max_len: int = MAX_LEN):\n",
    "    if not text.strip():\n",
    "        return \"desconocido\", 0.0\n",
    "    \n",
    "    sequence = tokenizer.texts_to_sequences([text.lower()])\n",
    "    padded = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded, verbose=0)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    return SENTIMENT_MAP_INV.get(predicted_class, \"desconocido\"), confidence\n",
    "\n",
    "file_path = 'fifa_tweets_clean.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo: {file_path}\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[df['sentiment_label'] != -1].dropna(subset=['test_clean', 'sentiment_label'])\n",
    "\n",
    "print(\"Dataset limpio cargado. Distribución de clases:\")\n",
    "print(df['sentiment_label'].value_counts(normalize=True))\n",
    "\n",
    "texts = df['test_clean'].astype(str).tolist()\n",
    "labels = df['sentiment_label'].astype(int).values\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "X = pad_sequences(tokenizer.texts_to_sequences(texts), maxlen=MAX_LEN)\n",
    "y = labels\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, stratify=y_train_val, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.01),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# ENTRENAMIENTO\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    callbacks=[early_stop], \n",
    "                    verbose=1)\n",
    "\n",
    "# EVALUATION\n",
    "plot_history(history, \"Modelo de Sentimientos\")\n",
    "y_true, y_pred = evaluate_model(model, X_test, y_test, TARGET_NAMES, \"Modelo de Sentimiento\")\n",
    "\n",
    "# EJEMPLO DE PREDICCIÓN\n",
    "ejemplo = \"This game was intense and exciting!\"\n",
    "sentimiento, confianza = predict_sentiment(ejemplo, model, tokenizer)\n",
    "print(f\"\\nEjemplo de predicción: \\\"{ejemplo}\\\"\")\n",
    "print(f\"Sentimiento: {sentimiento} ({confianza:.2%} confianza)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
